{\rtf1\ansi\ansicpg1252\cocoartf2513
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 HelveticaNeue;\f1\fnil\fcharset0 HelveticaNeue-Bold;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab560
\pard\pardeftab560\slleading20\partightenfactor0

\f0\fs24 \cf0 interact\
module load spark\
pyspark\
\
rdd1 = sc.textFile("pulsar.dat")\
rdd1.take(4) #works like .head for python\
\
rdd2 = rdd1.map(lambda x:x.split()) #splitting rdd1 by comma\
rdd2.take(4) #checking if rdd2 is now separated with comma\
\
\
rdd3 = rdd2.map(lambda x: [float(x[0]), float(x[1]), float(x[3])]) # taking out x,y,frequency so I can treat them as tuple, had to be float or if i use int it gives me an error\
rdd3.take(4) #checking that only timestamp was dropped\
\
rdd4 = rdd3.map(
\f1\b lambda
\f0\b0  x: tuple(round(val, 1) 
\f1\b for
\f0\b0  val 
\f1\b in
\f0\b0  x)) #rounding only up to 0.01, not ineger\
rdd4.take(4) #check if rounding to 0.1 worked\
\
rdd5 = rdd4.map(lambda x: (x,1))\
rdd5.take(4) #check if 1 has been added to later\
\
rdd6= rdd5.reduceByKey(lambda x,y: x+y) \
rdd6.take(10) #see if 1 at the end changed\
\
rdd7 = rdd6.map(lambda x: (x[1], x[0]))\
rdd7.take(4) #check if the count is in the front now\
\
rdd8 = rdd7.sortByKey(False)\
rdd8.take(4) #check the top order\
\
# we now know that max signal comes from 104.5, 82.1, 2231.5, we need to go back to original rdd_2 and include all \
\
rdd_x= rdd2.filter(lambda x: float(x[0]) >104.2 and float(x[0]) < 104.8) #using 3std, including all x in that range\
rdd_x.count() #count is just to check that the filtering is working properly\
rdd_y = rdd_x.filter(lambda x: float(x[1]) >81.8 and float(x[1]) < 82.4) #using 3std, including all y in that range\
rdd_y.count()\
rdd_f = rdd_y.filter(lambda x: float(x[3]) >2231.2 and float(x[3]) < 2231.8) #using 3std, including all frequencies in that range\
rdd_f.count() \
\
rdd_f.take(10)\
\
rdd_t = rdd_f.map(lambda x: (x[2], x[0], x[1], x[3])) #pulling the timestamp to the front\
rdd_t.take(4)\
\
rdd_t2 = rdd_t.sortByKey(True)\
\
rdd_time = rdd_t2.map(lambda x: (round(float(x[0]), 2), x[1], x[2], x[3])) #rounding the time stamp up to 0.01\
rdd_time.count() #checking how many i need to output, should be same number from rdd_f since we didn\'92t drop any \
rdd_time.take(33)}