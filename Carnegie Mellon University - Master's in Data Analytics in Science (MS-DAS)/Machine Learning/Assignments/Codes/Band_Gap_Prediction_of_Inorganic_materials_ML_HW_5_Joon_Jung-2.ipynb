{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Band Gap Prediction of Inorganic materials"
      ],
      "metadata": {
        "id": "qsbPB5C8gqKq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjW14kcVgepY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, ElasticNetCV, BayesianRidge\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, r2_score, make_scorer, mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_data = pd.read_csv('train_X.csv')\n",
        "y_train_data = pd.read_csv('train_y.csv')\n",
        "x_test_data = pd.read_csv('test_X.csv')\n",
        "\n",
        "x_train_data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "xadvPjskgwTi",
        "outputId": "22900bb0-2c17-4578-91fc-2c5bdd046024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Material  D1  D2  D3       D4        D5  D6  D7  D8  D9  ...  D124  \\\n",
              "0        O4V1Y1   8  39  31  15.6667  10.22220   8  12  87  75  ...   0.0   \n",
              "1  Al1Ba2Cu2F11   9  56  47  17.6250  12.43750   9   9  93  84  ...   0.0   \n",
              "2      Li2O2Pd1   3  46  43  13.6000  12.96000   3   1  87  86  ...   0.0   \n",
              "3  Br2Cl2Cu1Rb2  17  37  20  29.5714   7.34694  17   4  95  91  ...   0.0   \n",
              "4       Al1K1O2   8  19  11  12.0000   4.00000   8   3  87  84  ...   0.0   \n",
              "5     Br4Rb2Zn1  30  37   7  34.8571   1.38776  35   4  95  91  ...   0.0   \n",
              "6        B1O3V1   5  23  18  10.4000   5.04000   8  46  87  41  ...   0.0   \n",
              "7          C3O2   6   8   2   6.8000   0.96000   6  77  87  10  ...   0.0   \n",
              "8      Cu1Mg1P1  12  29  17  18.6667   6.88889  12  64  83  19  ...   0.0   \n",
              "9       K1P1Zn1  15  30  15  21.3333   5.77778  15   3  83  80  ...   0.0   \n",
              "\n",
              "   D125  D126  D127  D128  D129     D130      D131  D132     Id  \n",
              "0   0.0   0.0    12   229   217   78.500   88.6667    12   8683  \n",
              "1   0.0   0.0    15   229   214   81.125   90.9219    15   8788  \n",
              "2   0.0   0.0    12   229   217  141.400  103.5200    12   5144  \n",
              "3   0.0   0.0    64   229   165  134.143   80.1633    64   9593  \n",
              "4   0.0   0.0    12   229   217  119.500  107.5000    12   2027  \n",
              "5   0.0   0.0    64   229   165  129.714   75.1020    64  12996  \n",
              "6   0.0   0.0    12   229   217   86.200   89.0400    12   4653  \n",
              "7   0.0   0.0    12   194   182  121.200   87.3600   194   9758  \n",
              "8   0.0   0.0     2   225   223  140.333   92.2222     2   5078  \n",
              "9   0.0   0.0     2   229   227  141.667   93.1111     2   4146  \n",
              "\n",
              "[10 rows x 134 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2960de0-566f-43a4-9839-ca721525cbf6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Material</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>D124</th>\n",
              "      <th>D125</th>\n",
              "      <th>D126</th>\n",
              "      <th>D127</th>\n",
              "      <th>D128</th>\n",
              "      <th>D129</th>\n",
              "      <th>D130</th>\n",
              "      <th>D131</th>\n",
              "      <th>D132</th>\n",
              "      <th>Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>O4V1Y1</td>\n",
              "      <td>8</td>\n",
              "      <td>39</td>\n",
              "      <td>31</td>\n",
              "      <td>15.6667</td>\n",
              "      <td>10.22220</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>87</td>\n",
              "      <td>75</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>229</td>\n",
              "      <td>217</td>\n",
              "      <td>78.500</td>\n",
              "      <td>88.6667</td>\n",
              "      <td>12</td>\n",
              "      <td>8683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Al1Ba2Cu2F11</td>\n",
              "      <td>9</td>\n",
              "      <td>56</td>\n",
              "      <td>47</td>\n",
              "      <td>17.6250</td>\n",
              "      <td>12.43750</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>93</td>\n",
              "      <td>84</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15</td>\n",
              "      <td>229</td>\n",
              "      <td>214</td>\n",
              "      <td>81.125</td>\n",
              "      <td>90.9219</td>\n",
              "      <td>15</td>\n",
              "      <td>8788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Li2O2Pd1</td>\n",
              "      <td>3</td>\n",
              "      <td>46</td>\n",
              "      <td>43</td>\n",
              "      <td>13.6000</td>\n",
              "      <td>12.96000</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>87</td>\n",
              "      <td>86</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>229</td>\n",
              "      <td>217</td>\n",
              "      <td>141.400</td>\n",
              "      <td>103.5200</td>\n",
              "      <td>12</td>\n",
              "      <td>5144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Br2Cl2Cu1Rb2</td>\n",
              "      <td>17</td>\n",
              "      <td>37</td>\n",
              "      <td>20</td>\n",
              "      <td>29.5714</td>\n",
              "      <td>7.34694</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>95</td>\n",
              "      <td>91</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64</td>\n",
              "      <td>229</td>\n",
              "      <td>165</td>\n",
              "      <td>134.143</td>\n",
              "      <td>80.1633</td>\n",
              "      <td>64</td>\n",
              "      <td>9593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Al1K1O2</td>\n",
              "      <td>8</td>\n",
              "      <td>19</td>\n",
              "      <td>11</td>\n",
              "      <td>12.0000</td>\n",
              "      <td>4.00000</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>87</td>\n",
              "      <td>84</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>229</td>\n",
              "      <td>217</td>\n",
              "      <td>119.500</td>\n",
              "      <td>107.5000</td>\n",
              "      <td>12</td>\n",
              "      <td>2027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Br4Rb2Zn1</td>\n",
              "      <td>30</td>\n",
              "      <td>37</td>\n",
              "      <td>7</td>\n",
              "      <td>34.8571</td>\n",
              "      <td>1.38776</td>\n",
              "      <td>35</td>\n",
              "      <td>4</td>\n",
              "      <td>95</td>\n",
              "      <td>91</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64</td>\n",
              "      <td>229</td>\n",
              "      <td>165</td>\n",
              "      <td>129.714</td>\n",
              "      <td>75.1020</td>\n",
              "      <td>64</td>\n",
              "      <td>12996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>B1O3V1</td>\n",
              "      <td>5</td>\n",
              "      <td>23</td>\n",
              "      <td>18</td>\n",
              "      <td>10.4000</td>\n",
              "      <td>5.04000</td>\n",
              "      <td>8</td>\n",
              "      <td>46</td>\n",
              "      <td>87</td>\n",
              "      <td>41</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>229</td>\n",
              "      <td>217</td>\n",
              "      <td>86.200</td>\n",
              "      <td>89.0400</td>\n",
              "      <td>12</td>\n",
              "      <td>4653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>C3O2</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>6.8000</td>\n",
              "      <td>0.96000</td>\n",
              "      <td>6</td>\n",
              "      <td>77</td>\n",
              "      <td>87</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>194</td>\n",
              "      <td>182</td>\n",
              "      <td>121.200</td>\n",
              "      <td>87.3600</td>\n",
              "      <td>194</td>\n",
              "      <td>9758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Cu1Mg1P1</td>\n",
              "      <td>12</td>\n",
              "      <td>29</td>\n",
              "      <td>17</td>\n",
              "      <td>18.6667</td>\n",
              "      <td>6.88889</td>\n",
              "      <td>12</td>\n",
              "      <td>64</td>\n",
              "      <td>83</td>\n",
              "      <td>19</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>225</td>\n",
              "      <td>223</td>\n",
              "      <td>140.333</td>\n",
              "      <td>92.2222</td>\n",
              "      <td>2</td>\n",
              "      <td>5078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>K1P1Zn1</td>\n",
              "      <td>15</td>\n",
              "      <td>30</td>\n",
              "      <td>15</td>\n",
              "      <td>21.3333</td>\n",
              "      <td>5.77778</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>83</td>\n",
              "      <td>80</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>229</td>\n",
              "      <td>227</td>\n",
              "      <td>141.667</td>\n",
              "      <td>93.1111</td>\n",
              "      <td>2</td>\n",
              "      <td>4146</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 134 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2960de0-566f-43a4-9839-ca721525cbf6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f2960de0-566f-43a4-9839-ca721525cbf6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f2960de0-566f-43a4-9839-ca721525cbf6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9fa8cb9c-8b3c-4876-a2a4-5fb9c0002899\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9fa8cb9c-8b3c-4876-a2a4-5fb9c0002899')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9fa8cb9c-8b3c-4876-a2a4-5fb9c0002899 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "jpFfIAv_g2Yc",
        "outputId": "58fa6de9-558d-4aff-c14f-fa78e02c4528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Egap     Id\n",
              "0  2.8121   8683\n",
              "1  2.5128   8788\n",
              "2  1.9510   5144\n",
              "3  1.0099   9593\n",
              "4  2.9344   2027\n",
              "5  3.7766  12996\n",
              "6  1.4328   4653\n",
              "7  3.9189   9758\n",
              "8  0.1823   5078\n",
              "9  0.9864   4146"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17fa5822-5e9b-4cc2-b933-f9c472a8845e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Egap</th>\n",
              "      <th>Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.8121</td>\n",
              "      <td>8683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.5128</td>\n",
              "      <td>8788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.9510</td>\n",
              "      <td>5144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0099</td>\n",
              "      <td>9593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.9344</td>\n",
              "      <td>2027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3.7766</td>\n",
              "      <td>12996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.4328</td>\n",
              "      <td>4653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3.9189</td>\n",
              "      <td>9758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.1823</td>\n",
              "      <td>5078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.9864</td>\n",
              "      <td>4146</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17fa5822-5e9b-4cc2-b933-f9c472a8845e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-17fa5822-5e9b-4cc2-b933-f9c472a8845e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-17fa5822-5e9b-4cc2-b933-f9c472a8845e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-40c8b178-46bf-4ed2-ae89-441d52233582\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-40c8b178-46bf-4ed2-ae89-441d52233582')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-40c8b178-46bf-4ed2-ae89-441d52233582 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since I know the y_sample submission is formatted 'ID' column first, and then Egap, I am going to switch them here. I found that there is pandas function that does this for me."
      ],
      "metadata": {
        "id": "i2pbVLwShliC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_titles = [\"Id\",\"Egap\"]\n",
        "y_train_data=y_train_data.reindex(columns=columns_titles)\n",
        "y_train_data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "vYPUCyYQhtjw",
        "outputId": "35dace3b-1cb6-4fb6-b194-cf0de11d1c8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Id    Egap\n",
              "0   8683  2.8121\n",
              "1   8788  2.5128\n",
              "2   5144  1.9510\n",
              "3   9593  1.0099\n",
              "4   2027  2.9344\n",
              "5  12996  3.7766\n",
              "6   4653  1.4328\n",
              "7   9758  3.9189\n",
              "8   5078  0.1823\n",
              "9   4146  0.9864"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d251c98a-a4cf-4ec5-904b-8e691bf90819\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Egap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8683</td>\n",
              "      <td>2.8121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8788</td>\n",
              "      <td>2.5128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5144</td>\n",
              "      <td>1.9510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9593</td>\n",
              "      <td>1.0099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2027</td>\n",
              "      <td>2.9344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>12996</td>\n",
              "      <td>3.7766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4653</td>\n",
              "      <td>1.4328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>9758</td>\n",
              "      <td>3.9189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5078</td>\n",
              "      <td>0.1823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4146</td>\n",
              "      <td>0.9864</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d251c98a-a4cf-4ec5-904b-8e691bf90819')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d251c98a-a4cf-4ec5-904b-8e691bf90819 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d251c98a-a4cf-4ec5-904b-8e691bf90819');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2a0adaf0-3d10-48ae-9a73-80e8f01b2931\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2a0adaf0-3d10-48ae-9a73-80e8f01b2931')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2a0adaf0-3d10-48ae-9a73-80e8f01b2931 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning\n"
      ],
      "metadata": {
        "id": "fkv1m_DjuzoE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "More just like organizing things. I know that we won't have to do EDA or remove null values for this data set so we can skip those. We already switched the columns for y_train the ID column and Egap column to fit the format, so one step is done."
      ],
      "metadata": {
        "id": "WjSGAXevu28a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I know by looking at x_train_data set, that the material column won't help us in actual analysis, so let's just work with the properties D1-D130. We can also save the ID column for both x_train and y_train and add them back later, so we can just use numbers simply."
      ],
      "metadata": {
        "id": "RTfjJn-wuFf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = x_train_data[x_train_data.columns[1:-1]]\n",
        "y = y_train_data[y_train_data.columns[1:]]\n",
        "ID = x_test_data[x_test_data.columns[-1]]\n",
        "x_test = x_test_data[x_test_data.columns[1:-1]]"
      ],
      "metadata": {
        "id": "e_xxwOxbuFPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "Yvjuocl8vW1Q",
        "outputId": "2c68f0ae-aee6-4681-85f5-2b0b8a84c07b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   D1  D2  D3       D4        D5  D6  D7  D8  D9      D10  ...  D123  D124  \\\n",
              "0   8  39  31  15.6667  10.22220   8  12  87  75  67.6667  ...   0.0   0.0   \n",
              "1   9  56  47  17.6250  12.43750   9   9  93  84  77.6250  ...   0.0   0.0   \n",
              "2   3  46  43  13.6000  12.96000   3   1  87  86  47.6000  ...   0.0   0.0   \n",
              "3  17  37  20  29.5714   7.34694  17   4  95  91  64.2857  ...   0.0   0.0   \n",
              "4   8  19  11  12.0000   4.00000   8   3  87  84  62.5000  ...   0.0   0.0   \n",
              "5  30  37   7  34.8571   1.38776  35   4  95  91  65.2857  ...   0.0   0.0   \n",
              "6   5  23  18  10.4000   5.04000   8  46  87  41  75.8000  ...   0.0   0.0   \n",
              "7   6   8   2   6.8000   0.96000   6  77  87  10  81.0000  ...   0.0   0.0   \n",
              "8  12  29  17  18.6667   6.88889  12  64  83  19  71.6667  ...   0.0   0.0   \n",
              "9  15  30  15  21.3333   5.77778  15   3  83  80  51.6667  ...   0.0   0.0   \n",
              "\n",
              "   D125  D126  D127  D128  D129     D130      D131  D132  \n",
              "0   0.0   0.0    12   229   217   78.500   88.6667    12  \n",
              "1   0.0   0.0    15   229   214   81.125   90.9219    15  \n",
              "2   0.0   0.0    12   229   217  141.400  103.5200    12  \n",
              "3   0.0   0.0    64   229   165  134.143   80.1633    64  \n",
              "4   0.0   0.0    12   229   217  119.500  107.5000    12  \n",
              "5   0.0   0.0    64   229   165  129.714   75.1020    64  \n",
              "6   0.0   0.0    12   229   217   86.200   89.0400    12  \n",
              "7   0.0   0.0    12   194   182  121.200   87.3600   194  \n",
              "8   0.0   0.0     2   225   223  140.333   92.2222     2  \n",
              "9   0.0   0.0     2   229   227  141.667   93.1111     2  \n",
              "\n",
              "[10 rows x 132 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-182dd203-4260-4e71-b207-642d216ea00c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>D10</th>\n",
              "      <th>...</th>\n",
              "      <th>D123</th>\n",
              "      <th>D124</th>\n",
              "      <th>D125</th>\n",
              "      <th>D126</th>\n",
              "      <th>D127</th>\n",
              "      <th>D128</th>\n",
              "      <th>D129</th>\n",
              "      <th>D130</th>\n",
              "      <th>D131</th>\n",
              "      <th>D132</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>39</td>\n",
              "      <td>31</td>\n",
              "      <td>15.6667</td>\n",
              "      <td>10.22220</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>87</td>\n",
              "      <td>75</td>\n",
              "      <td>67.6667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>229</td>\n",
              "      <td>217</td>\n",
              "      <td>78.500</td>\n",
              "      <td>88.6667</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>56</td>\n",
              "      <td>47</td>\n",
              "      <td>17.6250</td>\n",
              "      <td>12.43750</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>93</td>\n",
              "      <td>84</td>\n",
              "      <td>77.6250</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15</td>\n",
              "      <td>229</td>\n",
              "      <td>214</td>\n",
              "      <td>81.125</td>\n",
              "      <td>90.9219</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>46</td>\n",
              "      <td>43</td>\n",
              "      <td>13.6000</td>\n",
              "      <td>12.96000</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>87</td>\n",
              "      <td>86</td>\n",
              "      <td>47.6000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>229</td>\n",
              "      <td>217</td>\n",
              "      <td>141.400</td>\n",
              "      <td>103.5200</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17</td>\n",
              "      <td>37</td>\n",
              "      <td>20</td>\n",
              "      <td>29.5714</td>\n",
              "      <td>7.34694</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>95</td>\n",
              "      <td>91</td>\n",
              "      <td>64.2857</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64</td>\n",
              "      <td>229</td>\n",
              "      <td>165</td>\n",
              "      <td>134.143</td>\n",
              "      <td>80.1633</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>19</td>\n",
              "      <td>11</td>\n",
              "      <td>12.0000</td>\n",
              "      <td>4.00000</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>87</td>\n",
              "      <td>84</td>\n",
              "      <td>62.5000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>229</td>\n",
              "      <td>217</td>\n",
              "      <td>119.500</td>\n",
              "      <td>107.5000</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>30</td>\n",
              "      <td>37</td>\n",
              "      <td>7</td>\n",
              "      <td>34.8571</td>\n",
              "      <td>1.38776</td>\n",
              "      <td>35</td>\n",
              "      <td>4</td>\n",
              "      <td>95</td>\n",
              "      <td>91</td>\n",
              "      <td>65.2857</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64</td>\n",
              "      <td>229</td>\n",
              "      <td>165</td>\n",
              "      <td>129.714</td>\n",
              "      <td>75.1020</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5</td>\n",
              "      <td>23</td>\n",
              "      <td>18</td>\n",
              "      <td>10.4000</td>\n",
              "      <td>5.04000</td>\n",
              "      <td>8</td>\n",
              "      <td>46</td>\n",
              "      <td>87</td>\n",
              "      <td>41</td>\n",
              "      <td>75.8000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>229</td>\n",
              "      <td>217</td>\n",
              "      <td>86.200</td>\n",
              "      <td>89.0400</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>6.8000</td>\n",
              "      <td>0.96000</td>\n",
              "      <td>6</td>\n",
              "      <td>77</td>\n",
              "      <td>87</td>\n",
              "      <td>10</td>\n",
              "      <td>81.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>194</td>\n",
              "      <td>182</td>\n",
              "      <td>121.200</td>\n",
              "      <td>87.3600</td>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>12</td>\n",
              "      <td>29</td>\n",
              "      <td>17</td>\n",
              "      <td>18.6667</td>\n",
              "      <td>6.88889</td>\n",
              "      <td>12</td>\n",
              "      <td>64</td>\n",
              "      <td>83</td>\n",
              "      <td>19</td>\n",
              "      <td>71.6667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>225</td>\n",
              "      <td>223</td>\n",
              "      <td>140.333</td>\n",
              "      <td>92.2222</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>15</td>\n",
              "      <td>30</td>\n",
              "      <td>15</td>\n",
              "      <td>21.3333</td>\n",
              "      <td>5.77778</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>83</td>\n",
              "      <td>80</td>\n",
              "      <td>51.6667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>229</td>\n",
              "      <td>227</td>\n",
              "      <td>141.667</td>\n",
              "      <td>93.1111</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 132 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-182dd203-4260-4e71-b207-642d216ea00c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-182dd203-4260-4e71-b207-642d216ea00c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-182dd203-4260-4e71-b207-642d216ea00c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-28c34595-bf5d-40fd-b04c-e01722c71f89\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-28c34595-bf5d-40fd-b04c-e01722c71f89')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-28c34595-bf5d-40fd-b04c-e01722c71f89 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "F8IRN3YhWes7",
        "outputId": "00d72668-1f84-46a6-b9e6-65b7d2550a03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Egap\n",
              "0  2.8121\n",
              "1  2.5128\n",
              "2  1.9510\n",
              "3  1.0099\n",
              "4  2.9344\n",
              "5  3.7766\n",
              "6  1.4328\n",
              "7  3.9189\n",
              "8  0.1823\n",
              "9  0.9864"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d9b7c714-1b31-4b7a-b5ab-8e4099a5f9bc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Egap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.8121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.5128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.9510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.9344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3.7766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.4328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3.9189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.1823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.9864</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9b7c714-1b31-4b7a-b5ab-8e4099a5f9bc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d9b7c714-1b31-4b7a-b5ab-8e4099a5f9bc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d9b7c714-1b31-4b7a-b5ab-8e4099a5f9bc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-af8288b7-ae7c-4dc0-b41b-62a71d3028ad\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-af8288b7-ae7c-4dc0-b41b-62a71d3028ad')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-af8288b7-ae7c-4dc0-b41b-62a71d3028ad button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ID.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oT8TgiNu9SD",
        "outputId": "24cc0fde-8503-4b59-f520-acdbb1cc5bca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    13062\n",
              "1      587\n",
              "2     2333\n",
              "3     7740\n",
              "4     9463\n",
              "5     5652\n",
              "6     8999\n",
              "7    11427\n",
              "8     3677\n",
              "9     2200\n",
              "Name: Id, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "AzIxgoBkvXCs",
        "outputId": "6009b20f-1dcb-40b8-c489-c787946c671c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   D1  D2  D3        D4       D5  D6  D7  D8  D9      D10  ...  D123  D124  \\\n",
              "0   6  79  73  23.66670  22.8889   6   4  82  78  64.6667  ...   0.0   0.0   \n",
              "1   6  11   5   7.00000   1.0000   6   2  82  80  69.5000  ...   0.0   0.0   \n",
              "2   6   6   0   6.00000   0.0000   6  77  77   0  77.0000  ...   0.0   0.0   \n",
              "3   1  16  15  10.00000   4.4000   9  83  93  10  89.8000  ...   0.0   0.0   \n",
              "4   6  56  50  22.66670  22.2222   6   9  77  68  54.3333  ...   0.0   0.0   \n",
              "5  37  52  15  45.00000   7.0000  52   4  90  86  53.6667  ...   0.0   0.0   \n",
              "6  15  55  40  27.00000  16.8000  15   5  83  78  59.6000  ...   0.0   0.0   \n",
              "7   1  12  11   2.72727   2.5124   1  68  92  24  86.1818  ...   0.0   0.0   \n",
              "8   1  48  47  13.20000  13.9200   1  70  92  22  85.6000  ...   0.0   0.0   \n",
              "9  34  92  58  55.75000  27.1875  34  20  89  69  63.1250  ...   0.0   0.0   \n",
              "\n",
              "   D125  D126  D127  D128  D129     D130      D131  D132  \n",
              "0   0.0   0.0   194   229    35  205.000  14.66670   194  \n",
              "1   0.0   0.0   194   229    35  198.375   7.65625   194  \n",
              "2   0.0   0.0   194   194     0  194.000   0.00000   194  \n",
              "3   0.0   0.0     2   194   192   59.200  58.24000    15  \n",
              "4   0.0   0.0   194   229    35  205.667  15.55560   194  \n",
              "5   0.0   0.0   152   229    77  184.667  32.66670   152  \n",
              "6   0.0   0.0     2   229   227   70.100  95.34000     2  \n",
              "7   0.0   0.0   166   194    28  188.909   8.33058   194  \n",
              "8   0.0   0.0    12   194   182  121.200  87.36000    12  \n",
              "9   0.0   0.0    14    63    49   32.375  22.96880    14  \n",
              "\n",
              "[10 rows x 132 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71303f3a-5cc2-4514-aadd-e4ad62116c2e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>D10</th>\n",
              "      <th>...</th>\n",
              "      <th>D123</th>\n",
              "      <th>D124</th>\n",
              "      <th>D125</th>\n",
              "      <th>D126</th>\n",
              "      <th>D127</th>\n",
              "      <th>D128</th>\n",
              "      <th>D129</th>\n",
              "      <th>D130</th>\n",
              "      <th>D131</th>\n",
              "      <th>D132</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>79</td>\n",
              "      <td>73</td>\n",
              "      <td>23.66670</td>\n",
              "      <td>22.8889</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>82</td>\n",
              "      <td>78</td>\n",
              "      <td>64.6667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>194</td>\n",
              "      <td>229</td>\n",
              "      <td>35</td>\n",
              "      <td>205.000</td>\n",
              "      <td>14.66670</td>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>7.00000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>82</td>\n",
              "      <td>80</td>\n",
              "      <td>69.5000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>194</td>\n",
              "      <td>229</td>\n",
              "      <td>35</td>\n",
              "      <td>198.375</td>\n",
              "      <td>7.65625</td>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>6</td>\n",
              "      <td>77</td>\n",
              "      <td>77</td>\n",
              "      <td>0</td>\n",
              "      <td>77.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>194</td>\n",
              "      <td>194</td>\n",
              "      <td>0</td>\n",
              "      <td>194.000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>15</td>\n",
              "      <td>10.00000</td>\n",
              "      <td>4.4000</td>\n",
              "      <td>9</td>\n",
              "      <td>83</td>\n",
              "      <td>93</td>\n",
              "      <td>10</td>\n",
              "      <td>89.8000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>194</td>\n",
              "      <td>192</td>\n",
              "      <td>59.200</td>\n",
              "      <td>58.24000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>56</td>\n",
              "      <td>50</td>\n",
              "      <td>22.66670</td>\n",
              "      <td>22.2222</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>77</td>\n",
              "      <td>68</td>\n",
              "      <td>54.3333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>194</td>\n",
              "      <td>229</td>\n",
              "      <td>35</td>\n",
              "      <td>205.667</td>\n",
              "      <td>15.55560</td>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>37</td>\n",
              "      <td>52</td>\n",
              "      <td>15</td>\n",
              "      <td>45.00000</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>52</td>\n",
              "      <td>4</td>\n",
              "      <td>90</td>\n",
              "      <td>86</td>\n",
              "      <td>53.6667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>152</td>\n",
              "      <td>229</td>\n",
              "      <td>77</td>\n",
              "      <td>184.667</td>\n",
              "      <td>32.66670</td>\n",
              "      <td>152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>15</td>\n",
              "      <td>55</td>\n",
              "      <td>40</td>\n",
              "      <td>27.00000</td>\n",
              "      <td>16.8000</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>83</td>\n",
              "      <td>78</td>\n",
              "      <td>59.6000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>229</td>\n",
              "      <td>227</td>\n",
              "      <td>70.100</td>\n",
              "      <td>95.34000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>2.72727</td>\n",
              "      <td>2.5124</td>\n",
              "      <td>1</td>\n",
              "      <td>68</td>\n",
              "      <td>92</td>\n",
              "      <td>24</td>\n",
              "      <td>86.1818</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>166</td>\n",
              "      <td>194</td>\n",
              "      <td>28</td>\n",
              "      <td>188.909</td>\n",
              "      <td>8.33058</td>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>47</td>\n",
              "      <td>13.20000</td>\n",
              "      <td>13.9200</td>\n",
              "      <td>1</td>\n",
              "      <td>70</td>\n",
              "      <td>92</td>\n",
              "      <td>22</td>\n",
              "      <td>85.6000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>194</td>\n",
              "      <td>182</td>\n",
              "      <td>121.200</td>\n",
              "      <td>87.36000</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>34</td>\n",
              "      <td>92</td>\n",
              "      <td>58</td>\n",
              "      <td>55.75000</td>\n",
              "      <td>27.1875</td>\n",
              "      <td>34</td>\n",
              "      <td>20</td>\n",
              "      <td>89</td>\n",
              "      <td>69</td>\n",
              "      <td>63.1250</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14</td>\n",
              "      <td>63</td>\n",
              "      <td>49</td>\n",
              "      <td>32.375</td>\n",
              "      <td>22.96880</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 132 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71303f3a-5cc2-4514-aadd-e4ad62116c2e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-71303f3a-5cc2-4514-aadd-e4ad62116c2e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-71303f3a-5cc2-4514-aadd-e4ad62116c2e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5c9eafde-360b-4455-a315-587a80cec460\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5c9eafde-360b-4455-a315-587a80cec460')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5c9eafde-360b-4455-a315-587a80cec460 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# changing it to ravel to use it for our analysis\n",
        "y = y.values.ravel()"
      ],
      "metadata": {
        "id": "fqvRNlpUWklE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's split the data here. I always found that depending on random seed state, the accuracy might differ, so I will be taking notes on which would be the best."
      ],
      "metadata": {
        "id": "076VjhV9v579"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(14)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=14)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_val = scaler.transform(x_val)\n"
      ],
      "metadata": {
        "id": "l7auUeOvv5XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Models"
      ],
      "metadata": {
        "id": "0sQ4bAYMnu5p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, I am going to first use numbers of Linear models we learned in class and try to predict and see how those models perform. I am first going to choose the general parameters for those models, and then if I find the one that performs well among others, then I will go into that model and do parameter tuning, or else I would have to do parameter tuning and grid search on every single model and compare."
      ],
      "metadata": {
        "id": "UhmV89Vrny_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note here that I took out Logistic Regression, because logistic regression was specifically designed for classification problems, and output will only be 0 and 1. Also for the metric, instead of F1 score that we used before, we are going to mean squared error, since this is not a classification problem."
      ],
      "metadata": {
        "id": "8JZDh9wbyN3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = [\n",
        "    #('Logistic Regression', LogisticRegression(max_iter=1000)),\n",
        "    ('Linear Regression', LinearRegression()),\n",
        "    ('Ridge Regression', Ridge(alpha=10.0)),  # adjust the alpha parameter\n",
        "    ('LASSO', Lasso(alpha=10.0)),  # adjust the alpha parameter\n",
        "    ('Elastic Net', ElasticNetCV(alphas=[0.1, 1.0, 10.0], l1_ratio=[0.1, 0.5, 0.9], cv=5))\n",
        "]"
      ],
      "metadata": {
        "id": "1YB4jZf7nuvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and compare the models\n",
        "best_model = None\n",
        "best_mse_score = 10.0\n",
        "best_r2_score = 0.0\n",
        "\n",
        "for name, model in models:\n",
        "    model.fit(x_train, y_train)\n",
        "    y_pred = model.predict(x_val)\n",
        "\n",
        "    # Round the predicted values\n",
        "    # y_pred = np.round(y_pred)\n",
        "\n",
        "    # Calculate Mean Squared Error\n",
        "    mse = mean_squared_error(y_val, y_pred)\n",
        "\n",
        "    # Calculate R-Squared value\n",
        "    r2 = r2_score(y_val, y_pred)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Model: {name}\")\n",
        "    print(f\"Mean Squared Error: {mse}\")\n",
        "    print(f\"R-squared: {r2}\")\n",
        "    print()\n",
        "\n",
        "    # Update best model based on MSE, smaller the MSE it is better, opposed to accuracy\n",
        "    if mse < best_mse_score and r2 > best_r2_score:\n",
        "        best_mse_score = mse\n",
        "        best_r2_score = r2\n",
        "        best_linear_model = model\n",
        "\n",
        "\n",
        "print(f\"Best Model (based on F1 Score): {best_linear_model}\")\n",
        "print(f\"Best MSE Score: {best_mse_score}\")\n",
        "print(f\"Best R-squared Score: {best_r2_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrZSTMo-pQq4",
        "outputId": "941ff3c6-d8cf-4d7e-ff2f-8af89f9ab047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Linear Regression\n",
            "Mean Squared Error: 1.1494237691896099\n",
            "R-squared: 0.535172131044811\n",
            "\n",
            "Model: Ridge Regression\n",
            "Mean Squared Error: 1.140584941769229\n",
            "R-squared: 0.5387465597490086\n",
            "\n",
            "Model: LASSO\n",
            "Mean Squared Error: 2.472803104268153\n",
            "R-squared: -3.5044630530833842e-06\n",
            "\n",
            "Model: Elastic Net\n",
            "Mean Squared Error: 1.205854981417612\n",
            "R-squared: 0.5123513047963735\n",
            "\n",
            "Best Model (based on F1 Score): Ridge(alpha=10.0)\n",
            "Best MSE Score: 1.140584941769229\n",
            "Best R-squared Score: 0.5387465597490086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, so it doesn't look too great using linear methods on this data set. We found that Ridge using alpha = 10.0, again this was generic choice just to compare with others, is the best model so far among linear models, with MSE 1.19 and R-squared value of 0.518, which is not the best. I could run the gridsearch just to find the best hyper parameter for this model, but I honestly think it wouldn't be too helpful than actually finding another model itself that would perform better. The purpose of this assignment was also to focus on the model engineering and finding the best model, so I will go ahead and find the best model, not try to make our bad model with Ridge better, with hyper parameter, for now. Who knows, maybe non linear methods won't perform better, then I will come back and do hyperparameter tuning on this."
      ],
      "metadata": {
        "id": "myc0s7a-7Qg0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Non Linear Methods\n"
      ],
      "metadata": {
        "id": "Pu1ddl2N88fP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try non linear methods. I have added more models that I found online while researching that might be most useful for us. I added the linear regression on top just so I can compare with others."
      ],
      "metadata": {
        "id": "p5NFGPrv8_rJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NV3GFWWsL_kP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
        "from scipy.optimize import curve_fit\n",
        "\n",
        "# Function to fit models that are not in scikit-learn\n",
        "def sigmoid(x, a, b, c):\n",
        "    return a / (1 + np.exp(-b * (x - c)))\n",
        "\n",
        "def exponential(x, a, b):\n",
        "    return a * np.exp(b * x)\n",
        "\n",
        "def logarithmic(x, a, b):\n",
        "    return a + b * np.log(x)\n",
        "\n",
        "def power_law(x, a, b):\n",
        "    return a * np.power(x, b)\n",
        "\n",
        "# Define models\n",
        "nonlinmodels = [\n",
        "    ('Ridge Regression', Ridge(alpha=10.0)), # just to compare with others\n",
        "    #('Polynomial Regression', make_pipeline(PolynomialFeatures(degree=2), LinearRegression())),\n",
        "    #('Exponential Regression', exponential),\n",
        "    #('Logarithmic Regression', logarithmic),\n",
        "    #('Power Law Regression', power_law),\n",
        "    #('Sigmoidal (Logistic) Regression', sigmoid),\n",
        "    #('Gaussian Process Regression', GaussianProcessRegressor(kernel=C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2)))),\n",
        "    ('Random Forest Regression', RandomForestRegressor()),\n",
        "    ('Gradient Boosting Regression', GradientBoostingRegressor()),\n",
        "    ('Support Vector Regression', SVR(kernel='rbf')),\n",
        "]\n",
        "\n",
        "# Fit models and evaluate performance\n",
        "best_model = None\n",
        "best_mse = 10.0\n",
        "best_r2 = 0.0\n",
        "\n",
        "for name, models in nonlinmodels:\n",
        "    if callable(models):\n",
        "        # For custom models (exponential, logarithmic, sigmoidal), use curve_fit\n",
        "        # The custom models that I made were all not working even after hours of trying to fix them, so I just decided not to use them.\n",
        "        # The function below still has components of it, because I didn't want to mess up the code too much, but you can see what I was trying to do\n",
        "        if models == exponential:\n",
        "            initial_params = [1.0, 0.1] #adjust parameters\n",
        "            popt, _ = curve_fit(model, x_train.values.T, y_train, p0=initial_params) #x_train.values.flatten()\n",
        "            y_pred = model(x_val.values.T, *popt)\n",
        "        else:\n",
        "          popt, _ = curve_fit(models, x_train, y_train) #x_train.flatten()\n",
        "          y_pred = models(x_val, *popt) #x_val.flatten()\n",
        "    else:\n",
        "        # For scikit-learn models\n",
        "        models.fit(x_train, y_train)\n",
        "        y_pred = models.predict(x_val)\n",
        "\n",
        "    mse = mean_squared_error(y_val, y_pred)\n",
        "    r2 = r2_score(y_val, y_pred)\n",
        "\n",
        "    print(f\"Model: {name}\")\n",
        "    print(f\"Mean Squared Error: {mse}\")\n",
        "    print(f\"R-squared: {r2}\\n\")\n",
        "\n",
        "    # Update best model if necessary\n",
        "    if mse < best_mse and r2 > best_r2:\n",
        "        best_nonlin_model = models\n",
        "        best_mse = mse\n",
        "        best_r2 = r2\n",
        "\n",
        "print(f\"Best Model: {best_nonlin_model}\")\n",
        "print(f\"Best Mean Squared Error: {best_mse}\")\n",
        "print(f\"Best R-squared: {best_r2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQsAfIrr9-On",
        "outputId": "3bec22b5-1342-4005-ae06-5d7b5375b355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Ridge Regression\n",
            "Mean Squared Error: 1.140584941769229\n",
            "R-squared: 0.5387465597490086\n",
            "\n",
            "Model: Random Forest Regression\n",
            "Mean Squared Error: 0.6246020542014703\n",
            "R-squared: 0.7474104420128714\n",
            "\n",
            "Model: Gradient Boosting Regression\n",
            "Mean Squared Error: 0.8213731328949803\n",
            "R-squared: 0.6678360642830596\n",
            "\n",
            "Model: Support Vector Regression\n",
            "Mean Squared Error: 0.8315090136847155\n",
            "R-squared: 0.6637371061844306\n",
            "\n",
            "Best Model: RandomForestRegressor()\n",
            "Best Mean Squared Error: 0.6246020542014703\n",
            "Best R-squared: 0.7474104420128714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seems like our Random Forest Model did the best so far. But MSE of 0.624 and R-squared of 0.747 still doesn't sound like the best. Let's try to do hyper parameter tuning for this model."
      ],
      "metadata": {
        "id": "L3JjK6OUMDXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "\n",
        "# Define the Random Forest model\n",
        "rf_model = RandomForestRegressor()\n",
        "\n",
        "# Define the hyperparameter grid to search\n",
        "param_grid = {\n",
        "    'n_estimators': [750, 800, 850, 900], # most commonly used are in range of 100 to 1000\n",
        "    'max_depth': [None, 10, 20, 30], # most commonly used are in range of 10 to 30\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2', 0.5, None],\n",
        "    'bootstrap': [True, False],\n",
        "    'criterion': ['squared_error', 'absolute_error'],\n",
        "    'max_samples': [0.5, 0.8, 1.0]\n",
        "    # Add other hyperparameters to tune\n",
        "}\n",
        "\n",
        "# Define the scoring metric (negative mean squared error in this case)\n",
        "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "grid_search = RandomizedSearchCV(rf_model, param_distributions=param_grid, n_iter=10, scoring=scorer, cv=5, error_score='raise', random_state=14, verbose=2)\n",
        "# changed scoring metric to neg mean squared error, and added error+score = raise to fix the error\n",
        "\n",
        "# Fit the GridSearchCV object to the data\n",
        "grid_search.fit(x_train, y_train) # Use ravel() to convert y_train to a 1D array and fix error\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Get the best model\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "y_pred = best_rf_model.predict(x_val)\n",
        "mse = mean_squared_error(y_val, y_pred)\n",
        "r2 = r2_score(y_val, y_pred)\n",
        "\n",
        "print(\"Best RF model\", best_rf_model)\n",
        "print(\"Best RF model MSE\", mse)\n",
        "print(\"Best RF model R-squared\", r2)\n"
      ],
      "metadata": {
        "id": "Q498SWbYMUFg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c8ae850-d715-401f-e32b-0a320fb72c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "[CV] END ...................................n_estimators=300; total time=  29.1s\n",
            "[CV] END ...................................n_estimators=300; total time=  29.3s\n",
            "[CV] END ...................................n_estimators=300; total time=  29.0s\n",
            "[CV] END ...................................n_estimators=300; total time=  29.7s\n",
            "[CV] END ...................................n_estimators=300; total time=  28.9s\n",
            "[CV] END ...................................n_estimators=400; total time=  38.4s\n",
            "[CV] END ...................................n_estimators=400; total time=  39.0s\n",
            "[CV] END ...................................n_estimators=400; total time=  38.9s\n",
            "[CV] END ...................................n_estimators=400; total time=  38.2s\n",
            "[CV] END ...................................n_estimators=400; total time=  37.6s\n",
            "[CV] END ...................................n_estimators=500; total time=  46.4s\n",
            "[CV] END ...................................n_estimators=500; total time=  47.1s\n",
            "[CV] END ...................................n_estimators=500; total time=  47.1s\n",
            "[CV] END ...................................n_estimators=500; total time=  46.9s\n",
            "[CV] END ...................................n_estimators=500; total time=  46.3s\n",
            "[CV] END ...................................n_estimators=600; total time=  56.1s\n",
            "[CV] END ...................................n_estimators=600; total time=  55.9s\n",
            "[CV] END ...................................n_estimators=600; total time=  56.5s\n",
            "[CV] END ...................................n_estimators=600; total time=  55.9s\n",
            "[CV] END ...................................n_estimators=600; total time=  56.5s\n",
            "[CV] END ...................................n_estimators=700; total time= 1.1min\n",
            "[CV] END ...................................n_estimators=700; total time= 1.1min\n",
            "[CV] END ...................................n_estimators=700; total time= 1.1min\n",
            "[CV] END ...................................n_estimators=700; total time= 1.1min\n",
            "[CV] END ...................................n_estimators=700; total time= 1.1min\n",
            "[CV] END ...................................n_estimators=800; total time= 1.2min\n",
            "[CV] END ...................................n_estimators=800; total time= 1.3min\n",
            "[CV] END ...................................n_estimators=800; total time= 1.2min\n",
            "[CV] END ...................................n_estimators=800; total time= 1.3min\n",
            "[CV] END ...................................n_estimators=800; total time= 1.2min\n",
            "Best Hyperparameters: {'n_estimators': 800}\n",
            "Best RF model RandomForestRegressor(n_estimators=800)\n",
            "Best RF model MSE 0.8019616983679211\n",
            "Best RF model R-squared 0.6767869481259683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, so with best hyper parameters, I wouldn't say that is an improvement. The code was taking so long for gridsearch, so I tried random search instead, I wonder if that is why. Still seems like A LOT of difference from others. I wonder how others got such low MSE score."
      ],
      "metadata": {
        "id": "-Rw0SWCnClpI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I wasn't going to use Neural Network, but it really seems like everyone else is getting incredible MSE score and I am almost double them. so I am going to see if my NN can do better than at least above result."
      ],
      "metadata": {
        "id": "I0fdAAf6DrpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name() #checking if it is running on GPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 58
        },
        "id": "-mnNJY1IDrXq",
        "outputId": "39a33bab-674b-461d-b2c1-8c87efd211f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install light-the-torch >> /.tmp\n",
        "!ltt install torch torchvision >> /.tmp\n",
        "!pip install fastai --upgrade >> /.tmp\n",
        "# Google colab kept telling me I am not using GPU even when I have set GPU as runtime processor, so I wanted to run this just in case."
      ],
      "metadata": {
        "id": "_4INpaoGEJsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, make_scorer\n",
        "\n",
        "# Define the MLPRegressor model\n",
        "mlp_model = MLPRegressor(random_state=14)\n",
        "\n",
        "# Define the hyperparameter grid to search\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100)],\n",
        "    'activation': ['relu', 'logistic', 'tanh'],\n",
        "    'alpha': [0.0001, 0.001, 0.01],\n",
        "    'max_iter': [500, 1000, 1500],\n",
        "}\n",
        "\n",
        "# Define the scoring metric (negative mean squared error in this case)\n",
        "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "grid_search = GridSearchCV(mlp_model, param_grid, scoring=scorer, cv=5, error_score='raise', verbose=2)\n",
        "\n",
        "# Fit the GridSearchCV object to the data\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Get the best model\n",
        "best_mlp_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred = best_mlp_model.predict(x_val)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_val, y_pred)\n",
        "r2 = r2_score(y_val, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Best MLP model MSE:\", mse)\n",
        "print(\"Best MLP model R-squared:\", r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1R3YtQY8ETqk",
        "outputId": "88297b4f-fbc9-4679-c02c-0c9a7e1908b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=500; total time=   3.4s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=500; total time=   3.5s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=500; total time=   7.2s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=500; total time=   3.6s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=500; total time=   4.0s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1000; total time=   4.2s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1000; total time=   6.8s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1000; total time=   9.6s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1000; total time=   6.3s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1000; total time=   7.6s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1500; total time=   6.1s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1500; total time=   5.4s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1500; total time=   7.9s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1500; total time=   6.5s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1500; total time=   9.7s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=500; total time=   6.0s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=500; total time=   9.2s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=500; total time=  10.6s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=500; total time=   4.7s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=500; total time=   4.4s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1000; total time=   6.2s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1000; total time=   4.5s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1000; total time=   5.4s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1000; total time=   6.2s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1000; total time=   4.1s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1500; total time=   4.4s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1500; total time=   6.7s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1500; total time=   4.5s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1500; total time=   6.8s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1500; total time=   4.7s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=500; total time=   4.6s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=500; total time=   8.2s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=500; total time=   5.5s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=500; total time=   6.4s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=500; total time=   6.3s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=   5.5s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=   7.4s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=   5.5s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=   6.6s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=   5.8s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=   6.4s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=   6.8s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=   6.7s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=   5.6s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=   5.8s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=500; total time=   7.5s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=500; total time=   4.7s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=500; total time=   3.7s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=500; total time=   9.7s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=500; total time=   5.9s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=   7.1s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=   4.8s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=   5.4s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=   8.1s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=   8.2s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=   5.3s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=   4.7s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=   6.2s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=   7.3s\n",
            "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=   8.1s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), max_iter=500; total time=   3.5s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), max_iter=500; total time=   4.1s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), max_iter=500; total time=   6.9s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), max_iter=500; total time=   3.5s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), max_iter=500; total time=   3.1s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1000; total time=   5.1s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1000; total time=   5.2s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1000; total time=   4.2s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1000; total time=   4.9s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1000; total time=   4.4s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1500; total time=   3.4s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1500; total time=   4.1s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1500; total time=   6.7s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1500; total time=   3.6s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1500; total time=   3.1s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), max_iter=500; total time=   6.6s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), max_iter=500; total time=   4.7s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), max_iter=500; total time=   4.6s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), max_iter=500; total time=   7.0s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), max_iter=500; total time=   3.4s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1000; total time=   3.9s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1000; total time=   7.1s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1000; total time=   4.5s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1000; total time=   4.4s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1000; total time=   5.9s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1500; total time=  12.7s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1500; total time=   7.5s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1500; total time=   6.4s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1500; total time=   5.4s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1500; total time=   3.5s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=500; total time=   6.8s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=500; total time=   7.4s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=500; total time=   4.6s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=500; total time=   6.2s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=500; total time=   4.9s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=   8.4s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=   7.2s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=   6.2s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=   4.5s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=   6.1s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=   6.5s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=   7.5s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=   6.0s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=   4.6s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=   5.0s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=500; total time=   6.2s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=500; total time=   5.2s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=500; total time=   7.9s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=500; total time=   6.7s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=500; total time=   7.5s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=   4.1s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=   5.4s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=   8.0s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=   6.7s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=   7.5s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=   4.1s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=   7.6s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=   5.7s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=   9.2s\n",
            "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=   5.0s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), max_iter=500; total time=   3.4s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), max_iter=500; total time=   5.9s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), max_iter=500; total time=   3.4s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), max_iter=500; total time=   3.6s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), max_iter=500; total time=   3.3s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1000; total time=   6.0s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1000; total time=   3.5s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1000; total time=   3.1s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1000; total time=   4.9s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1000; total time=   4.4s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1500; total time=   3.3s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1500; total time=   3.4s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1500; total time=   5.7s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1500; total time=   3.5s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1500; total time=   3.3s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), max_iter=500; total time=   3.8s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), max_iter=500; total time=   6.2s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), max_iter=500; total time=   4.7s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), max_iter=500; total time=   5.0s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), max_iter=500; total time=   5.2s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1000; total time=   3.6s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1000; total time=   3.8s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1000; total time=   7.3s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1000; total time=   4.4s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1000; total time=   3.3s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1500; total time=   6.1s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1500; total time=   3.8s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1500; total time=   4.6s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1500; total time=   6.6s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1500; total time=   3.4s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=500; total time=   5.0s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=500; total time=   7.9s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=500; total time=   4.5s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=500; total time=   7.9s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=500; total time=   5.2s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1000; total time=   6.3s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1000; total time=   6.3s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1000; total time=   4.4s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1000; total time=   8.2s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1000; total time=   7.6s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1500; total time=  15.4s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1500; total time=   7.7s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1500; total time=   4.5s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1500; total time=   8.0s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1500; total time=   5.5s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=500; total time=   7.7s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=500; total time=   8.0s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=500; total time=   8.5s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=500; total time=   4.3s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=500; total time=  12.5s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1000; total time=   4.9s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1000; total time=   7.6s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1000; total time=   5.4s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1000; total time=   6.2s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1000; total time=   7.1s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1500; total time=   5.6s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1500; total time=   6.9s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1500; total time=   5.4s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  11.2s\n",
            "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  12.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=500; total time=   5.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=500; total time=   9.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=500; total time=  13.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=500; total time=   5.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=500; total time=   8.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1000; total time=  14.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1000; total time=  14.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1000; total time=  16.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1000; total time=  14.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1000; total time=  14.1s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1500; total time=  15.6s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1500; total time=  14.4s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1500; total time=  15.0s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1500; total time=  19.1s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1500; total time=  23.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=500; total time=  11.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=500; total time=  11.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=500; total time=  10.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=500; total time=  13.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=500; total time=  14.3s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1000; total time=  17.7s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1000; total time=  16.6s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1000; total time=  31.1s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1000; total time=  19.6s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1000; total time=  19.5s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1500; total time=  19.2s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1500; total time=  21.8s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1500; total time=  19.8s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1500; total time=  30.1s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1500; total time=  23.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=500; total time=  18.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=500; total time=  12.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=500; total time=  15.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=500; total time=  14.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=500; total time=  14.1s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  16.6s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  30.8s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  21.8s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  25.2s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  13.3s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=  18.0s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=  14.7s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=  15.8s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=  16.5s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=  11.2s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=500; total time=  16.0s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=500; total time=  20.4s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=500; total time=  16.6s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=500; total time=  13.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=500; total time=  19.0s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  15.4s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  19.9s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  17.9s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  12.5s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  22.1s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  14.7s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  18.4s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  16.1s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  12.8s\n",
            "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  20.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), max_iter=500; total time=   9.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), max_iter=500; total time=   6.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), max_iter=500; total time=   9.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), max_iter=500; total time=   6.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), max_iter=500; total time=   9.1s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1000; total time=  14.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1000; total time=  22.8s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1000; total time=  15.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1000; total time=  15.3s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1000; total time=  14.6s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1500; total time=  14.9s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1500; total time=  20.4s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1500; total time=  21.3s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1500; total time=  18.9s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1500; total time=  16.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), max_iter=500; total time=  10.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), max_iter=500; total time=  11.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), max_iter=500; total time=  11.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), max_iter=500; total time=   8.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), max_iter=500; total time=  11.2s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1000; total time=  19.3s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1000; total time=  22.2s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1000; total time=  17.8s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1000; total time=  17.9s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1000; total time=  22.7s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1500; total time=  16.0s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1500; total time=  16.2s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1500; total time=  17.8s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1500; total time=  19.3s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1500; total time=  17.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=500; total time=   9.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=500; total time=  11.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=500; total time=  11.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=500; total time=  11.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=500; total time=   9.4s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  33.8s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  18.3s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  13.2s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  27.1s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  11.3s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=  14.6s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=  13.6s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=  12.5s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=  17.1s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=  12.5s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=500; total time=  14.3s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=500; total time=  17.5s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=500; total time=  17.4s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=500; total time=  12.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=500; total time=  18.9s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  13.7s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  19.2s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  15.1s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  12.2s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  20.0s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  13.9s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  17.5s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  15.5s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  13.0s\n",
            "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  19.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), max_iter=500; total time=   8.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), max_iter=500; total time=   5.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), max_iter=500; total time=   8.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), max_iter=500; total time=   5.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), max_iter=500; total time=   8.6s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1000; total time=  14.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1000; total time=  14.6s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1000; total time=  14.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1000; total time=  14.0s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1000; total time=  10.8s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1500; total time=  14.1s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1500; total time=  15.5s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1500; total time=  14.5s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1500; total time=  15.6s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1500; total time=  12.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), max_iter=500; total time=  11.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), max_iter=500; total time=  11.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), max_iter=500; total time=   9.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), max_iter=500; total time=  11.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), max_iter=500; total time=  11.4s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1000; total time=  16.4s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1000; total time=  16.4s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1000; total time=  15.2s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1000; total time=  15.2s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1000; total time=  17.8s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1500; total time=  17.6s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1500; total time=  17.1s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1500; total time=  15.2s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1500; total time=  15.3s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1500; total time=  17.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=500; total time=  11.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=500; total time=   8.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=500; total time=  11.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=500; total time=  11.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=500; total time=  11.4s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  14.1s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  12.7s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  13.1s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  15.0s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  11.7s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1500; total time=  14.4s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1500; total time=  13.8s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1500; total time=  13.8s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1500; total time=  15.1s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1500; total time=  14.4s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=500; total time=  13.9s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=500; total time=  27.6s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=500; total time=  22.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=500; total time=  21.8s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=500; total time=  17.0s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  14.2s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  17.7s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  17.0s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  22.7s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  17.1s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  13.6s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  17.3s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  17.3s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  23.3s\n",
            "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  17.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=500; total time=  10.9s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=500; total time=   6.4s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=500; total time=  10.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=500; total time=   9.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=500; total time=   9.4s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1000; total time=  11.3s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1000; total time=   6.9s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1000; total time=  10.1s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1000; total time=  11.3s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1000; total time=  12.1s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1500; total time=   8.7s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1500; total time=   8.9s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1500; total time=   8.8s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1500; total time=  10.4s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), max_iter=1500; total time=  12.1s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=500; total time=  11.2s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=500; total time=  12.6s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=500; total time=  11.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=500; total time=  17.3s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=500; total time=  16.3s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1000; total time=   8.8s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1000; total time=  13.2s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1000; total time=  12.9s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1000; total time=  16.5s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1000; total time=  15.6s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1500; total time=  11.2s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1500; total time=  12.9s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1500; total time=  13.1s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1500; total time=  16.1s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), max_iter=1500; total time=  15.6s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=500; total time=  11.6s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=500; total time=   5.0s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=500; total time=  12.5s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=500; total time=  10.2s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=500; total time=  10.3s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  11.3s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=   6.0s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  11.2s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  10.1s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  12.4s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=   9.6s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=   7.2s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=  12.4s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=   7.8s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=  12.2s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=500; total time=  15.4s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=500; total time=  15.1s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=500; total time=  14.9s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=500; total time=  11.9s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=500; total time=  13.7s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  15.5s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  14.9s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  14.3s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  12.0s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  13.2s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  15.8s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  15.0s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  14.5s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=   9.3s\n",
            "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  13.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), max_iter=500; total time=  11.1s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), max_iter=500; total time=   7.5s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), max_iter=500; total time=   9.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), max_iter=500; total time=  10.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), max_iter=500; total time=   9.9s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1000; total time=   9.8s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1000; total time=   9.0s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1000; total time=   7.9s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1000; total time=  11.3s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1000; total time=  12.1s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1500; total time=  11.2s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1500; total time=   6.3s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1500; total time=  10.4s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1500; total time=   9.9s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), max_iter=1500; total time=  11.2s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), max_iter=500; total time=  11.3s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), max_iter=500; total time=  13.0s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), max_iter=500; total time=  13.1s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), max_iter=500; total time=  14.6s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), max_iter=500; total time=  13.4s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1000; total time=   8.8s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1000; total time=  12.8s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1000; total time=  13.0s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1000; total time=  14.4s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1000; total time=  13.4s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1500; total time=  11.2s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1500; total time=  12.3s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1500; total time=  11.2s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1500; total time=  14.5s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), max_iter=1500; total time=  13.3s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=500; total time=  11.6s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=500; total time=   5.1s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=500; total time=  11.9s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=500; total time=  10.2s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=500; total time=  12.3s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=   9.1s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=   7.7s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  12.4s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=   7.7s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  12.4s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=  11.9s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=   5.0s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=  12.1s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=  10.3s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50, 50), max_iter=1500; total time=  10.3s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=500; total time=  16.0s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=500; total time=  15.7s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=500; total time=  13.8s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=500; total time=  10.7s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=500; total time=  13.6s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  15.2s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  15.3s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  14.7s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  11.9s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  13.6s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  15.4s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  15.2s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  14.3s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  11.9s\n",
            "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  13.6s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), max_iter=500; total time=   5.8s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), max_iter=500; total time=   8.9s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), max_iter=500; total time=   7.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), max_iter=500; total time=  11.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), max_iter=500; total time=  11.0s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1000; total time=   6.2s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1000; total time=   8.7s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1000; total time=   7.9s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1000; total time=  11.2s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1000; total time=  12.0s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1500; total time=   5.9s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1500; total time=   9.2s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1500; total time=   9.5s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1500; total time=   9.7s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), max_iter=1500; total time=  12.0s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), max_iter=500; total time=  11.3s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), max_iter=500; total time=  12.7s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), max_iter=500; total time=  10.9s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), max_iter=500; total time=  12.8s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), max_iter=500; total time=  15.3s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1000; total time=  11.1s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1000; total time=  12.9s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1000; total time=  13.4s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1000; total time=  12.9s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1000; total time=  15.2s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1500; total time=   8.8s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1500; total time=  12.9s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1500; total time=  12.9s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1500; total time=  12.9s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), max_iter=1500; total time=  15.3s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=500; total time=  11.5s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=500; total time=   5.0s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=500; total time=  11.5s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=500; total time=   8.8s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=500; total time=  11.7s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  11.5s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1000; total time=   5.8s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  10.3s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  10.3s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1000; total time=  12.9s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1500; total time=   9.0s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1500; total time=   7.5s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1500; total time=  10.1s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1500; total time=   8.5s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50, 50), max_iter=1500; total time=  13.1s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=500; total time=  15.2s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=500; total time=  15.5s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=500; total time=   9.8s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=500; total time=  10.4s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=500; total time=  12.6s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  15.7s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  15.3s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1000; total time=   9.3s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  11.8s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1000; total time=  13.6s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  15.4s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  15.0s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1500; total time=   8.4s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  11.0s\n",
            "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 100), max_iter=1500; total time=  13.9s\n",
            "Best Hyperparameters: {'activation': 'logistic', 'alpha': 0.01, 'hidden_layer_sizes': (50,), 'max_iter': 500}\n",
            "Best MLP model MSE: 1.0376854600979972\n",
            "Best MLP model R-squared: 0.58178366232933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wow, after like two hours of running hyper parameter tuning, I am at 1.03768 MSE and 0.58178 R-squared. Not best. Let me actually make models myself and see how it does."
      ],
      "metadata": {
        "id": "zbNCR4Xicu2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, BatchNormalization, Dropout, Flatten, LeakyReLU\n",
        "\n",
        "from tensorflow.keras.losses import mean_squared_error\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import random"
      ],
      "metadata": {
        "id": "F1k7h8JYMnyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(14)\n",
        "tf.random.set_seed(14)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.001, random_state=14)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_val = scaler.transform(x_val)\n",
        "\n",
        "\n",
        "#X_train = x_train.reshape(x_train.shape[], 32, 32, 1)\n",
        "#X_test = x_val.reshape(x_val.shape[], 32, 32, 1)\n",
        "#X_train = X_train / 255.0\n",
        "#X_test = X_test / 255.0\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1, activation = 'linear'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss = 'mean_squared_error', optimizer = tf.keras.optimizers.Adam(0.001), metrics = ['mean_squared_error'])\n",
        "\n"
      ],
      "metadata": {
        "id": "3OOWvK9QH9Fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_model = model.fit(x_train, y_train, epochs=30, batch_size=1024, validation_data=(x_val, y_val), verbose=1)\n",
        "\n",
        "y_pred = model.predict(x_val)\n",
        "mse_nn = mean_squared_error(y_val.T, y_pred)\n",
        "overall_mse_nn = np.mean(mse_nn) #idk why but the above line worked for every single model, but for this one it gave me every single element difference, so I had to add this line\n",
        "\n",
        "r2_nn = r2_score(y_val, y_pred)\n",
        "\n",
        "print(\"Neural Network Regression\")\n",
        "print(f\"Mean Squared Error: {overall_mse_nn}\")\n",
        "print(f\"R-squared: {r2_nn}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpRgef9Vdu-3",
        "outputId": "e5ad08b4-c4fd-472a-9990-ef72009f0608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "10/10 [==============================] - 14s 1s/step - loss: 9.6887 - mean_squared_error: 9.6887 - val_loss: 8.3691 - val_mean_squared_error: 8.3691\n",
            "Epoch 2/30\n",
            "10/10 [==============================] - 12s 1s/step - loss: 5.1493 - mean_squared_error: 5.1493 - val_loss: 2.5296 - val_mean_squared_error: 2.5296\n",
            "Epoch 3/30\n",
            "10/10 [==============================] - 10s 985ms/step - loss: 1.7437 - mean_squared_error: 1.7437 - val_loss: 2.1997 - val_mean_squared_error: 2.1997\n",
            "Epoch 4/30\n",
            "10/10 [==============================] - 11s 1s/step - loss: 1.3166 - mean_squared_error: 1.3166 - val_loss: 1.2015 - val_mean_squared_error: 1.2015\n",
            "Epoch 5/30\n",
            "10/10 [==============================] - 11s 1s/step - loss: 1.1083 - mean_squared_error: 1.1083 - val_loss: 0.9763 - val_mean_squared_error: 0.9763\n",
            "Epoch 6/30\n",
            "10/10 [==============================] - 11s 1s/step - loss: 1.0257 - mean_squared_error: 1.0257 - val_loss: 0.7923 - val_mean_squared_error: 0.7923\n",
            "Epoch 7/30\n",
            "10/10 [==============================] - 10s 949ms/step - loss: 0.9391 - mean_squared_error: 0.9391 - val_loss: 0.7683 - val_mean_squared_error: 0.7683\n",
            "Epoch 8/30\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.8717 - mean_squared_error: 0.8717 - val_loss: 0.6347 - val_mean_squared_error: 0.6347\n",
            "Epoch 9/30\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.8118 - mean_squared_error: 0.8118 - val_loss: 0.6188 - val_mean_squared_error: 0.6188\n",
            "Epoch 10/30\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.7861 - mean_squared_error: 0.7861 - val_loss: 0.6753 - val_mean_squared_error: 0.6753\n",
            "Epoch 11/30\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.7396 - mean_squared_error: 0.7396 - val_loss: 0.5561 - val_mean_squared_error: 0.5561\n",
            "Epoch 12/30\n",
            "10/10 [==============================] - 15s 1s/step - loss: 0.6912 - mean_squared_error: 0.6912 - val_loss: 0.9014 - val_mean_squared_error: 0.9014\n",
            "Epoch 13/30\n",
            "10/10 [==============================] - 10s 960ms/step - loss: 0.7041 - mean_squared_error: 0.7041 - val_loss: 0.7557 - val_mean_squared_error: 0.7557\n",
            "Epoch 14/30\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.6460 - mean_squared_error: 0.6460 - val_loss: 0.6147 - val_mean_squared_error: 0.6147\n",
            "Epoch 15/30\n",
            "10/10 [==============================] - 13s 1s/step - loss: 0.6208 - mean_squared_error: 0.6208 - val_loss: 0.6810 - val_mean_squared_error: 0.6810\n",
            "Epoch 16/30\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.5746 - mean_squared_error: 0.5746 - val_loss: 0.6909 - val_mean_squared_error: 0.6909\n",
            "Epoch 17/30\n",
            "10/10 [==============================] - 10s 960ms/step - loss: 0.5748 - mean_squared_error: 0.5748 - val_loss: 0.6689 - val_mean_squared_error: 0.6689\n",
            "Epoch 18/30\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.5481 - mean_squared_error: 0.5481 - val_loss: 0.5690 - val_mean_squared_error: 0.5690\n",
            "Epoch 19/30\n",
            "10/10 [==============================] - 15s 2s/step - loss: 0.5088 - mean_squared_error: 0.5088 - val_loss: 0.6507 - val_mean_squared_error: 0.6507\n",
            "Epoch 20/30\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.5133 - mean_squared_error: 0.5133 - val_loss: 0.5227 - val_mean_squared_error: 0.5227\n",
            "Epoch 21/30\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.5255 - mean_squared_error: 0.5255 - val_loss: 0.4877 - val_mean_squared_error: 0.4877\n",
            "Epoch 22/30\n",
            "10/10 [==============================] - 10s 946ms/step - loss: 0.4941 - mean_squared_error: 0.4941 - val_loss: 0.6553 - val_mean_squared_error: 0.6553\n",
            "Epoch 23/30\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.4688 - mean_squared_error: 0.4688 - val_loss: 0.4692 - val_mean_squared_error: 0.4692\n",
            "Epoch 24/30\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.4302 - mean_squared_error: 0.4302 - val_loss: 0.7029 - val_mean_squared_error: 0.7029\n",
            "Epoch 25/30\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.4257 - mean_squared_error: 0.4257 - val_loss: 0.9062 - val_mean_squared_error: 0.9062\n",
            "Epoch 26/30\n",
            "10/10 [==============================] - 10s 940ms/step - loss: 0.4218 - mean_squared_error: 0.4218 - val_loss: 0.5079 - val_mean_squared_error: 0.5079\n",
            "Epoch 27/30\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.3782 - mean_squared_error: 0.3782 - val_loss: 0.8246 - val_mean_squared_error: 0.8246\n",
            "Epoch 28/30\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.3765 - mean_squared_error: 0.3765 - val_loss: 0.7031 - val_mean_squared_error: 0.7031\n",
            "Epoch 29/30\n",
            "10/10 [==============================] - 10s 967ms/step - loss: 0.3804 - mean_squared_error: 0.3804 - val_loss: 0.6423 - val_mean_squared_error: 0.6423\n",
            "Epoch 30/30\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.3433 - mean_squared_error: 0.3433 - val_loss: 0.6401 - val_mean_squared_error: 0.6401\n",
            "1/1 [==============================] - 0s 213ms/step\n",
            "Neural Network Regression\n",
            "Mean Squared Error: 5.185797691345215\n",
            "R-squared: 0.767250705645522\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_val[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gk4-p2rEmoKO",
        "outputId": "8fb65ad1-3d7e-400a-b405-3a7153541630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5931 6.8304 1.9915 3.6904 3.1902 1.6664 1.6269 2.121  1.3687 2.2024]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred[:10, :].T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz2bNE-EnfxZ",
        "outputId": "e820b81e-ac77-4033-eea5-ce0bd0244f62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.5535884 6.6014676 1.864155  4.234812  3.682961  1.3218606 1.8279066\n",
            "  1.7219428 2.5928597 1.8379807]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_mse = nn_model.history['mean_squared_error']\n",
        "val_mse = nn_model.history['val_mean_squared_error']\n",
        "\n",
        "# Plot the training and validation MSE\n",
        "epochs = range(1, len(train_mse) + 1)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs, train_mse, label='Train MSE')\n",
        "plt.plot(epochs, val_mse, label='Validation MSE')\n",
        "plt.title('Training and Validation Mean Squared Error')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "IY_UKVQhiIkd",
        "outputId": "6e0cde60-fb9d-43cd-b1b9-4af02de879ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, that does look like it is better than the previous methods. Not sure if my mean squared error is correct here though, it looks way too small. It says its around mean squared error of 1 later on, but that is not what i got on leaderboard also."
      ],
      "metadata": {
        "id": "YaSyAHBBCJtN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# File Output\n"
      ],
      "metadata": {
        "id": "H4RIHbAGt7NM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's output the excel files. First, let's output our neural network file that did the best."
      ],
      "metadata": {
        "id": "agPZ-ttuxG3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# x_test data should already be loaded\n",
        "x_test_scaled = scaler.transform(x_test)  # Scale the test data using the same scalers\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_test_pred = model.predict(x_test_scaled)\n",
        "\n",
        "# Create a DataFrame with the predicted labels\n",
        "ID = x_test_data[x_test_data.columns[-1]]\n",
        "ID_df = pd.DataFrame({'Id': ID})\n",
        "result_df = pd.DataFrame({'Egap': y_test_pred.ravel()}) #had to add ravel since y_test_pred shape was (4132,1)\n",
        "combined_df = pd.concat([ID_df, result_df], axis=1)\n",
        "\n",
        "# Save the results to a CSV file (replace 'results.csv' with your desired file name)\n",
        "combined_df.to_csv('nn_results.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpOHMWjIt93A",
        "outputId": "e0d03c6b-b8fa-4f03-b124-c602eba578ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130/130 [==============================] - 3s 20ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am also going to output the best linear and non linear models that we found using hyperparameter tuning, just to see how they do on the leaderboard."
      ],
      "metadata": {
        "id": "htZiTAfJCjyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# x_test data should already be loaded, and scaled\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_test_pred = best_linear_model.predict(x_test_scaled)\n",
        "\n",
        "# Create a DataFrame with the predicted labels\n",
        "ID = x_test_data[x_test_data.columns[-1]]\n",
        "ID_df = pd.DataFrame({'Id': ID})\n",
        "result_df = pd.DataFrame({'Egap': y_test_pred})\n",
        "combined_df = pd.concat([ID, result_df], axis=1)\n",
        "\n",
        "# Save the results to a CSV file (replace 'results.csv' with your desired file name)\n",
        "combined_df.to_csv('linear_results.csv', index=False)\n"
      ],
      "metadata": {
        "id": "-Uc6gAvJxFlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x_test data should already be loaded, and scaled\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_test_pred = best_nonlin_model.predict(x_test_scaled)\n",
        "\n",
        "# Create a DataFrame with the predicted labels\n",
        "ID = x_test_data[x_test_data.columns[-1]]\n",
        "ID_df = pd.DataFrame({'Id': ID})\n",
        "result_df = pd.DataFrame({'Egap': y_test_pred})\n",
        "combined_df = pd.concat([ID, result_df], axis=1)\n",
        "\n",
        "# Save the results to a CSV file (replace 'results.csv' with your desired file name)\n",
        "combined_df.to_csv('nonlinear_results.csv', index=False)\n"
      ],
      "metadata": {
        "id": "8aTYMll53Vz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I guess I could just keep trying more and more hyper parameters and trying to improve the MSE on leaderboard, but it took me so long to get here, and with so many parameters, both gridsearch and randomsearch takes so long like hours, that I decided it is good to cut here. I may try some late submissions just to see how some other methods do after playing around with other parameters."
      ],
      "metadata": {
        "id": "rYSFvv9FCr-s"
      }
    }
  ]
}